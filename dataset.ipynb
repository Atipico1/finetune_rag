{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 592/592 [00:00<00:00, 2.54MB/s]\n",
      "Downloading data: 100%|██████████| 253M/253M [00:55<00:00, 4.55MB/s] \n",
      "Downloading data: 100%|██████████| 254M/254M [00:43<00:00, 5.85MB/s] \n",
      "Generating train split: 100%|██████████| 97888/97888 [00:01<00:00, 51607.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"Seongill/SQuAD_unique_questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'masked_query', 'query_embedding'],\n",
       "        num_rows: 97888\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['subset', 'context', 'qid', 'question', 'detected_answers', 'answers', 'query_embedding'],\n",
       "    num_rows: 253798\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"query_embedding\", \"qid\", \"question\",'detected_answers', 'answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_246328/2514229723.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subdf[\"context_word_count\"] = subdf.context.apply(lambda x: len(x.split()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQuAD 119.78705943856151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_246328/2514229723.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subdf[\"context_word_count\"] = subdf.context.apply(lambda x: len(x.split()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TriviaQA-web 673.4499599819048\n",
      "SearchQA 646.9646711258778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_246328/2514229723.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subdf[\"context_word_count\"] = subdf.context.apply(lambda x: len(x.split()))\n"
     ]
    }
   ],
   "source": [
    "for subset in df.subset.unique():\n",
    "    subdf = df[df.subset == subset]\n",
    "    subdf[\"context_word_count\"] = subdf.context.apply(lambda x: len(x.split()))\n",
    "    print(subset, subdf.context_word_count.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 253798/253798 [00:56<00:00, 4522.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "sub_dataset = dataset.filter(lambda example: example[\"subset\"] == \"SearchQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646.9646711258778"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctxs = []\n",
    "for row in sub_dataset[\"train\"]:\n",
    "    ctx = row[\"context\"]\n",
    "    ctxs.append(len(ctx.split()))\n",
    "sum(ctxs) / len(ctxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ctxs = []\n",
    "for row in dataset[\"train\"]:\n",
    "    new_ctxs.append(sorted(row[\"ctxs\"], key=lambda x: x[\"score\"], reverse=True)[:5])\n",
    "dataset[\"train\"] = dataset[\"train\"].remove_columns([\"ctxs\"])\n",
    "dataset[\"train\"] = dataset[\"train\"].add_column(\"ctxs\", new_ctxs)\n",
    "new_ctxs = []\n",
    "for row in dataset[\"test\"]:\n",
    "    new_ctxs.append(sorted(row[\"ctxs\"], key=lambda x: x[\"score\"], reverse=True)[:5])\n",
    "dataset[\"test\"] = dataset[\"test\"].remove_columns([\"ctxs\"])\n",
    "dataset[\"test\"] = dataset[\"test\"].add_column(\"ctxs\", new_ctxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 88/88 [00:00<00:00, 90.16ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:22<00:00, 22.65s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 90.07ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Atipico1/NQ/commit/f64681264c74eaef4a9f75ed1c1639a9192663e7', commit_message='Upload dataset', commit_description='', oid='f64681264c74eaef4a9f75ed1c1639a9192663e7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"Atipico1/NQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"train\"][0]['ctxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hasanswer': False,\n",
       "  'id': '12820371',\n",
       "  'score': 1.2165672,\n",
       "  'text': 'on death row in the United States on January 1, 2013. Since 1977, the states of Texas (464), Virginia (108) and Oklahoma (94) have executed the most death row inmates. , California (683), Florida (390), Texas (330) and Pennsylvania (218) housed more than half of all inmates pending on death row. , the longest-serving prisoner on death row in the US who has been executed was Jack Alderman who served over 33 years. He was executed in Georgia in 2008. However, Alderman only holds the distinction of being the longest-serving \"executed\" inmate so far. A Florida inmate, Gary Alvord, arrived',\n",
       "  'title': 'Death row'},\n",
       " {'hasanswer': False,\n",
       "  'id': '2457140',\n",
       "  'score': 1.1802328,\n",
       "  'text': 'people, and Gary Lee Sampson who was sentenced to death a second time in 2017 for two carjacking murders (after an original 2003 death sentence for the same crimes was vacated in 2011). As of September 28, 2018, there are 63 offenders on federal death row, most of them at Federal Correctional Complex in Terre Haute, Indiana. The only woman on federal death row as of 2018, Lisa M. Montgomery, is held at Federal Medical Center, Carswell, in Fort Worth, Texas. , aside from those at Terre Haute, three male death row inmates are held at ADX Florence, two are',\n",
       "  'title': 'Capital punishment by the United States federal government'},\n",
       " {'hasanswer': False,\n",
       "  'id': '17689323',\n",
       "  'score': 1.1727095,\n",
       "  'text': \"murder, with the exception of Ethel Rosenberg who was sentenced to death for espionage. Women on death row have a relatively low chance of actually being executed: there have only been 571 documented executions from 1632 to 2012. Currently, about half of the women on death row are in the top five states for death row sentencing (California, Florida, Texas, North Carolina and Ohio). Although California is the top state for death sentences, no woman has been executed since 1962. Although both men and women suffer from mental issues at approximately the same rate, they don't experience the same disorders.\",\n",
       "  'title': 'Incarceration of women in the United States'},\n",
       " {'hasanswer': False,\n",
       "  'id': '6762996',\n",
       "  'score': 1.1683524,\n",
       "  'text': 'to be 113 per 100,000 for the period 1976–1999. This is about ten times the rate of suicide in the United States as a whole and about six times the rate of suicide in the general U.S. prison population. Since the re-institution of the death penalty in 1976 to January 1, 2017, 145 prisoners have waived their appeals and asked that the execution be carried out. In the post-\"Furman\" era, four states (Connecticut, New Mexico, Oregon, and Pennsylvania) have executed only volunteers. The theory of the death row phenomenon may be traced to 1989, when the European Court of Human',\n",
       "  'title': 'Death row phenomenon'},\n",
       " {'hasanswer': False,\n",
       "  'id': '2456648',\n",
       "  'score': 1.1667547,\n",
       "  'text': '1976. However, this is an under-representation relative to the proportion of convicted murderers; 52.5% of all homicide offenders between 1980 and 2008 were African Americans. According to a 2003 Amnesty International report, blacks and whites were the victims of murder in almost equal numbers. Approximately 13.5% of death row inmates are of Hispanic or Latino descent, while they make up 17.4% of the general population. As of October 1, 2016, the Death Penalty Information Center reports that there are only 54 women on death row. This constitutes 1.86% of the total death row population. 16 women have been executed since',\n",
       "  'title': 'Capital punishment in the United States'},\n",
       " {'hasanswer': False,\n",
       "  'id': '2456649',\n",
       "  'score': 1.1367356,\n",
       "  'text': '1976, while 1442 men have been executed. 15,391 total confirmed lawful executions have been carried out in the US since 1608, and of these, 575, or 3.6%, were women. Women account for 1/50 death sentences, 1/67 people on death row, and 1/100 people whose executions are actually carried out. The states that have executed the most women are California, Texas and Florida. For women, the racial breakdown of those sentenced to death is 21% black, 13% Latina, 2% American Indian, 61% white and 3% Asian. All 30 states with the death penalty provide lethal injection as the primary method of',\n",
       "  'title': 'Capital punishment in the United States'},\n",
       " {'hasanswer': False,\n",
       "  'id': '9987825',\n",
       "  'score': 1.1131008,\n",
       "  'text': 'death row has about 290 prisoners. As of March 2013 eight male death row prisoners are housed in Jester IV Unit, a psychiatric unit, instead of Polunsky. The state of Texas began housing death row inmates in the Huntsville Unit in 1928. In 1965 the male death row inmates moved to the Ellis Unit. In 1999 the male death row moved to Polunsky. In the 1923-1973 period Texas state authorities had three female death row inmates; the first, Emma \"Straight Eight\" Oliver, was held at Huntsville Unit after her 1949 sentencing, but had her sentence commuted to life imprisonment in',\n",
       "  'title': 'Texas Department of Criminal Justice'},\n",
       " {'hasanswer': False,\n",
       "  'id': '12820370',\n",
       "  'score': 1.1081429,\n",
       "  'text': 'commit suicide. In the United States, prisoners may wait many years before execution can be carried out due to the complex and time-consuming appeals procedures mandated in the jurisdiction. The time between sentencing and execution has increased relatively steadily between 1977 and 2010, including a 22% jump between 1989 and 1990 and a similar jump between 2008 and 2009. In 2010, a death row inmate waited an average of 178 months (roughly 15 years) between sentencing and execution. Nearly a quarter of inmates on death row in the U.S. die of natural causes while awaiting execution. There were 3,125 people',\n",
       "  'title': 'Death row'},\n",
       " {'hasanswer': False,\n",
       "  'id': '12970124',\n",
       "  'score': 1.0984373,\n",
       "  'text': 'a criminal sentence. Of those thirty-six states, Texas executed the most inmates during 2009 with 24 executions. The total number of executions in the United States in 2009 was 52. In 2009, the total number of inmates serving a death sentence in the United States was 3,173. Many executions are delayed as inmates seek appeals to overturn sentences or convictions. Advances in science and in particular, DNA testing, have yielded more accurate forensic evidence. In some cases, post-conviction testing has helped innocent people establish that they were wrongfully convicted and to gain exonerations. In the process, comparisons to state and',\n",
       "  'title': 'Innocence Protection Act'},\n",
       " {'hasanswer': False,\n",
       "  'id': '11343821',\n",
       "  'score': 1.0934942,\n",
       "  'text': \"single cells in the segregation unit. The William E. Donaldson Correctional Facility has a male death row with a capacity of 24. Donaldson's death row houses prisoners who need to stay in the Birmingham judicial district. Julia Tutwiler Prison for Women houses the female death row. All executions occur at Holman. From 1983 to April 2018, Alabama has executed 63 people. As of 2018, Alabama had 191 inmates on death row, the 4th highest number in the US. A governor has commuted only one death sentence since 1976: outgoing Governor Fob James commuted Judith Ann Neelley's death sentence to life\",\n",
       "  'title': 'Capital punishment in Alabama'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]['ctxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"context_tokens\",\"question_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 133/133 [00:00<00:00, 155.45ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 133/133 [00:01<00:00, 71.20ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [00:56<00:00, 28.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Atipico1/mrqa_squad-tqa-sqa/commit/176968afba56204c53a661fa4138c67e086a8b35', commit_message='Upload dataset', commit_description='', oid='176968afba56204c53a661fa4138c67e086a8b35', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"Atipico1/mrqa_squad-tqa-sqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/seongilpark/conda_envs/ft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading data: 100%|██████████| 116M/116M [00:44<00:00, 2.58MB/s] \n",
      "Downloading data: 100%|██████████| 106M/106M [00:47<00:00, 2.25MB/s] \n",
      "Downloading data: 100%|██████████| 202M/202M [01:13<00:00, 2.76MB/s] \n",
      "Downloading data: 100%|██████████| 205M/205M [01:13<00:00, 2.80MB/s] \n",
      "Downloading data: 100%|██████████| 202M/202M [01:10<00:00, 2.84MB/s] \n",
      "Downloading data: 100%|██████████| 202M/202M [01:20<00:00, 2.51MB/s] \n",
      "Downloading data: 100%|██████████| 204M/204M [01:20<00:00, 2.51MB/s] \n",
      "Downloading data: 100%|██████████| 221M/221M [01:27<00:00, 2.52MB/s] \n",
      "Downloading data: 100%|██████████| 26.7M/26.7M [00:11<00:00, 2.30MB/s]\n",
      "Downloading data: 100%|██████████| 15.5M/15.5M [00:05<00:00, 2.70MB/s]\n",
      "Downloading data: 100%|██████████| 178M/178M [01:10<00:00, 2.50MB/s] \n",
      "Generating train split: 516819 examples [00:09, 55321.25 examples/s] \n",
      "Generating test split: 9633 examples [00:00, 73470.55 examples/s]\n",
      "Generating validation split: 58221 examples [00:01, 50898.19 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mrqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SQuAD', 'NewsQA', 'TriviaQA-web', 'SearchQA', 'HotpotQA',\n",
       "       'NaturalQuestionsShort'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset</th>\n",
       "      <th>context</th>\n",
       "      <th>context_tokens</th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>question_tokens</th>\n",
       "      <th>detected_answers</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subset, context, context_tokens, qid, question, question_tokens, detected_answers, answers]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.subset == \"TriviaQA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset</th>\n",
       "      <th>context</th>\n",
       "      <th>context_tokens</th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>question_tokens</th>\n",
       "      <th>detected_answers</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQuAD</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>{'tokens': ['Architecturally', ',', 'the', 'sc...</td>\n",
       "      <td>38cc2597b6624bd8af1e8ba7f693096f</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'tokens': ['To', 'whom', 'did', 'the', 'Virgi...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'char...</td>\n",
       "      <td>[Saint Bernadette Soubirous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SQuAD</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>{'tokens': ['Architecturally', ',', 'the', 'sc...</td>\n",
       "      <td>b17a05e67fd14669860a380d66aed5fb</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'tokens': ['What', 'is', 'in', 'front', 'of',...</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'char_...</td>\n",
       "      <td>[a copper statue of Christ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SQuAD</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>{'tokens': ['Architecturally', ',', 'the', 'sc...</td>\n",
       "      <td>80a511ed750842d08ecdfaaaa257d95f</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'tokens': ['The', 'Basilica', 'of', 'the', 'S...</td>\n",
       "      <td>{'text': ['the Main Building'], 'char_spans': ...</td>\n",
       "      <td>[the Main Building]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SQuAD</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>{'tokens': ['Architecturally', ',', 'the', 'sc...</td>\n",
       "      <td>913477b8e7f84432a16e1594219815e5</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'tokens': ['What', 'is', 'the', 'Grotto', 'at...</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "      <td>[a Marian place of prayer and reflection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SQuAD</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>{'tokens': ['Architecturally', ',', 'the', 'sc...</td>\n",
       "      <td>1c969af40a3248eb87a6d8c9c7c8d4ad</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'tokens': ['What', 'sits', 'on', 'top', 'of',...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "      <td>[a golden statue of the Virgin Mary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339815</th>\n",
       "      <td>SearchQA</td>\n",
       "      <td>[DOC] [TLE] RPubs - What Is This Obscure Quest...</td>\n",
       "      <td>{'tokens': ['[DOC]', '[TLE]', 'RPubs', '-', 'W...</td>\n",
       "      <td>75de6544c0044658b5e4b1ac0abefa61</td>\n",
       "      <td>In North America this term is properly applied...</td>\n",
       "      <td>{'tokens': ['In', 'North', 'America', 'this', ...</td>\n",
       "      <td>{'text': ['a titmouse'], 'char_spans': [{'star...</td>\n",
       "      <td>[a titmouse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339816</th>\n",
       "      <td>SearchQA</td>\n",
       "      <td>[DOC] [TLE] RPubs - What Is This Obscure Quest...</td>\n",
       "      <td>{'tokens': ['[DOC]', '[TLE]', 'RPubs', '-', 'W...</td>\n",
       "      <td>965a796bb4ef4eb38886290bdab56dd1</td>\n",
       "      <td>In 2006 the cast of this long-running hit emba...</td>\n",
       "      <td>{'tokens': ['In', '2006', 'the', 'cast', 'of',...</td>\n",
       "      <td>{'text': ['Stomp'], 'char_spans': [{'start': [...</td>\n",
       "      <td>[Stomp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339817</th>\n",
       "      <td>SearchQA</td>\n",
       "      <td>[DOC] [TLE] songbird | bird | Britannica.com [...</td>\n",
       "      <td>{'tokens': ['[DOC]', '[TLE]', 'songbird', '|',...</td>\n",
       "      <td>f932dd62ec5148cc8facb52b454b6036</td>\n",
       "      <td>Nightingales &amp; robins belong to this family of...</td>\n",
       "      <td>{'tokens': ['Nightingales', '&amp;', 'robins', 'be...</td>\n",
       "      <td>{'text': ['thrushes'], 'char_spans': [{'start'...</td>\n",
       "      <td>[thrushes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339818</th>\n",
       "      <td>SearchQA</td>\n",
       "      <td>[DOC] [TLE] RPubs - What Is This Obscure Quest...</td>\n",
       "      <td>{'tokens': ['[DOC]', '[TLE]', 'RPubs', '-', 'W...</td>\n",
       "      <td>57dc90f250d645d0a4bdeaed422f2059</td>\n",
       "      <td>This Puccini opera turns on the solution to 3 ...</td>\n",
       "      <td>{'tokens': ['This', 'Puccini', 'opera', 'turns...</td>\n",
       "      <td>{'text': ['Turandot'], 'char_spans': [{'start'...</td>\n",
       "      <td>[Turandot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339819</th>\n",
       "      <td>SearchQA</td>\n",
       "      <td>[DOC] [TLE] Game Show NewsNet - Jeopardy! Tour...</td>\n",
       "      <td>{'tokens': ['[DOC]', '[TLE]', 'Game', 'Show', ...</td>\n",
       "      <td>4b0a634b898c42fcace0b39a370936f3</td>\n",
       "      <td>Guyanese capital named for a Hanoverian monarch</td>\n",
       "      <td>{'tokens': ['Guyanese', 'capital', 'named', 'f...</td>\n",
       "      <td>{'text': ['Georgetown'], 'char_spans': [{'star...</td>\n",
       "      <td>[Georgetown]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265660 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subset                                            context  \\\n",
       "0          SQuAD  Architecturally, the school has a Catholic cha...   \n",
       "1          SQuAD  Architecturally, the school has a Catholic cha...   \n",
       "2          SQuAD  Architecturally, the school has a Catholic cha...   \n",
       "3          SQuAD  Architecturally, the school has a Catholic cha...   \n",
       "4          SQuAD  Architecturally, the school has a Catholic cha...   \n",
       "...          ...                                                ...   \n",
       "339815  SearchQA  [DOC] [TLE] RPubs - What Is This Obscure Quest...   \n",
       "339816  SearchQA  [DOC] [TLE] RPubs - What Is This Obscure Quest...   \n",
       "339817  SearchQA  [DOC] [TLE] songbird | bird | Britannica.com [...   \n",
       "339818  SearchQA  [DOC] [TLE] RPubs - What Is This Obscure Quest...   \n",
       "339819  SearchQA  [DOC] [TLE] Game Show NewsNet - Jeopardy! Tour...   \n",
       "\n",
       "                                           context_tokens  \\\n",
       "0       {'tokens': ['Architecturally', ',', 'the', 'sc...   \n",
       "1       {'tokens': ['Architecturally', ',', 'the', 'sc...   \n",
       "2       {'tokens': ['Architecturally', ',', 'the', 'sc...   \n",
       "3       {'tokens': ['Architecturally', ',', 'the', 'sc...   \n",
       "4       {'tokens': ['Architecturally', ',', 'the', 'sc...   \n",
       "...                                                   ...   \n",
       "339815  {'tokens': ['[DOC]', '[TLE]', 'RPubs', '-', 'W...   \n",
       "339816  {'tokens': ['[DOC]', '[TLE]', 'RPubs', '-', 'W...   \n",
       "339817  {'tokens': ['[DOC]', '[TLE]', 'songbird', '|',...   \n",
       "339818  {'tokens': ['[DOC]', '[TLE]', 'RPubs', '-', 'W...   \n",
       "339819  {'tokens': ['[DOC]', '[TLE]', 'Game', 'Show', ...   \n",
       "\n",
       "                                     qid  \\\n",
       "0       38cc2597b6624bd8af1e8ba7f693096f   \n",
       "1       b17a05e67fd14669860a380d66aed5fb   \n",
       "2       80a511ed750842d08ecdfaaaa257d95f   \n",
       "3       913477b8e7f84432a16e1594219815e5   \n",
       "4       1c969af40a3248eb87a6d8c9c7c8d4ad   \n",
       "...                                  ...   \n",
       "339815  75de6544c0044658b5e4b1ac0abefa61   \n",
       "339816  965a796bb4ef4eb38886290bdab56dd1   \n",
       "339817  f932dd62ec5148cc8facb52b454b6036   \n",
       "339818  57dc90f250d645d0a4bdeaed422f2059   \n",
       "339819  4b0a634b898c42fcace0b39a370936f3   \n",
       "\n",
       "                                                 question  \\\n",
       "0       To whom did the Virgin Mary allegedly appear i...   \n",
       "1       What is in front of the Notre Dame Main Building?   \n",
       "2       The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                       What is the Grotto at Notre Dame?   \n",
       "4       What sits on top of the Main Building at Notre...   \n",
       "...                                                   ...   \n",
       "339815  In North America this term is properly applied...   \n",
       "339816  In 2006 the cast of this long-running hit emba...   \n",
       "339817  Nightingales & robins belong to this family of...   \n",
       "339818  This Puccini opera turns on the solution to 3 ...   \n",
       "339819    Guyanese capital named for a Hanoverian monarch   \n",
       "\n",
       "                                          question_tokens  \\\n",
       "0       {'tokens': ['To', 'whom', 'did', 'the', 'Virgi...   \n",
       "1       {'tokens': ['What', 'is', 'in', 'front', 'of',...   \n",
       "2       {'tokens': ['The', 'Basilica', 'of', 'the', 'S...   \n",
       "3       {'tokens': ['What', 'is', 'the', 'Grotto', 'at...   \n",
       "4       {'tokens': ['What', 'sits', 'on', 'top', 'of',...   \n",
       "...                                                   ...   \n",
       "339815  {'tokens': ['In', 'North', 'America', 'this', ...   \n",
       "339816  {'tokens': ['In', '2006', 'the', 'cast', 'of',...   \n",
       "339817  {'tokens': ['Nightingales', '&', 'robins', 'be...   \n",
       "339818  {'tokens': ['This', 'Puccini', 'opera', 'turns...   \n",
       "339819  {'tokens': ['Guyanese', 'capital', 'named', 'f...   \n",
       "\n",
       "                                         detected_answers  \\\n",
       "0       {'text': ['Saint Bernadette Soubirous'], 'char...   \n",
       "1       {'text': ['a copper statue of Christ'], 'char_...   \n",
       "2       {'text': ['the Main Building'], 'char_spans': ...   \n",
       "3       {'text': ['a Marian place of prayer and reflec...   \n",
       "4       {'text': ['a golden statue of the Virgin Mary'...   \n",
       "...                                                   ...   \n",
       "339815  {'text': ['a titmouse'], 'char_spans': [{'star...   \n",
       "339816  {'text': ['Stomp'], 'char_spans': [{'start': [...   \n",
       "339817  {'text': ['thrushes'], 'char_spans': [{'start'...   \n",
       "339818  {'text': ['Turandot'], 'char_spans': [{'start'...   \n",
       "339819  {'text': ['Georgetown'], 'char_spans': [{'star...   \n",
       "\n",
       "                                          answers  \n",
       "0                    [Saint Bernadette Soubirous]  \n",
       "1                     [a copper statue of Christ]  \n",
       "2                             [the Main Building]  \n",
       "3       [a Marian place of prayer and reflection]  \n",
       "4            [a golden statue of the Virgin Mary]  \n",
       "...                                           ...  \n",
       "339815                               [a titmouse]  \n",
       "339816                                    [Stomp]  \n",
       "339817                                 [thrushes]  \n",
       "339818                                 [Turandot]  \n",
       "339819                               [Georgetown]  \n",
       "\n",
       "[265660 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df[df.subset.isin(['SQuAD','TriviaQA-web', 'SearchQA'])]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "sub_dataset = Dataset.from_pandas(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dataset\n",
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (7/7 shards): 100%|██████████| 265660/265660 [00:02<00:00, 122061.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "sub_dataset.save_to_disk(\"mrqa_subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 638/638 [00:00<00:00, 2.94MB/s]\n",
      "Downloading data: 100%|██████████| 168M/168M [00:38<00:00, 4.37MB/s] \n",
      "Downloading data: 100%|██████████| 168M/168M [00:32<00:00, 5.24MB/s] \n",
      "Downloading data: 100%|██████████| 13.8M/13.8M [00:02<00:00, 6.49MB/s]\n",
      "Generating train split: 100%|██████████| 87925/87925 [00:01<00:00, 60877.23 examples/s]\n",
      "Generating test split: 100%|██████████| 3610/3610 [00:00<00:00, 58019.17 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answers', 'ctxs'],\n",
       "        num_rows: 87925\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answers', 'ctxs'],\n",
       "        num_rows: 3610\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(\"Seongill/nq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 967/967 [00:00<00:00, 3.73MB/s]\n",
      "tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 17.4MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.80M/1.80M [00:01<00:00, 1.79MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 72.0/72.0 [00:00<00:00, 417kB/s]\n",
      "config.json: 100%|██████████| 571/571 [00:00<00:00, 1.23MB/s]\n",
      "model.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 43.2MB/s]\n",
      "model-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [14:15<00:00, 11.6MB/s]\n",
      "model-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [06:31<00:00, 11.6MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [20:47<00:00, 623.60s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n",
      "generation_config.json: 100%|██████████| 116/116 [00:00<00:00, 557kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
